{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set headers\n",
    "heads = requests.utils.default_headers()\n",
    "heads.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n",
    "   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to retrieve detials about each post\n",
    "def getUser(header):\n",
    "    user = ''\n",
    "    user_tag = header.find(\"a\", class_=\"user\")\n",
    "    if user_tag:\n",
    "        user_tag.get_text()\n",
    "    return user\n",
    "\n",
    "def getTimestamp(header):\n",
    "    time = ''\n",
    "    date = ''\n",
    "    tag_datetime = header.contents[-1]\n",
    "    if tag_datetime:\n",
    "        time = tag_datetime.contents[0].contents[0]\n",
    "    if len(tag_datetime.contents) == 3:\n",
    "        date = tag_datetime.contents[-1].contents[0]\n",
    "    elif len(tag_datetime.contents) == 6:\n",
    "        date = tag_datetime.contents[2].contents[0] + ' ' + tag_datetime.contents[4].contents[0]\n",
    "    date_time = '{} {}'.format(date, time) \n",
    "    return date_time\n",
    "\n",
    "def getLikesShares(body):\n",
    "    likes = ''\n",
    "    shares = ''\n",
    "    s_class = body.find(\"p\", class_='s')\n",
    "    if s_class:\n",
    "        likes = s_class.find_all('b')[0].get_text()\n",
    "        shares = s_class.find_all('b')[1].get_text()\n",
    "    return [likes, shares]\n",
    "\n",
    "def getQuote(body):\n",
    "    quotes = []\n",
    "    content = body.find('div', class_='narrow')\n",
    "    blockquotes = content.find_all('blockquote')\n",
    "    for blockquote in blockquotes:\n",
    "        a_tag = blockquote.find('a')\n",
    "        if a_tag:\n",
    "            _id = a_tag.get('href')\n",
    "            quotes.append(_id)\n",
    "    return quotes\n",
    "\n",
    "def getText(body):\n",
    "    content = body.find('div', class_='narrow')\n",
    "    text = ''\n",
    "    while content.blockquote:\n",
    "        content.blockquote.extract()\n",
    "    text = content.get_text()\n",
    "    return text\n",
    "\n",
    "def getPostID(header):\n",
    "    post_id = ''\n",
    "    name = header.find_all('a')[0].get('name')\n",
    "    if name:\n",
    "        post_id = name\n",
    "    return post_id\n",
    "\n",
    "def is_post_equal(post1, post2):\n",
    "    return post1 == post2\n",
    "\n",
    "def get_thread(link):\n",
    "    _id = ''\n",
    "    name = link.get('name')\n",
    "    if name not in ('top', None):\n",
    "        _id = name\n",
    "    return _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve details of each post\n",
    "def parse_post(header, body):\n",
    "    post = {}\n",
    "    post['posted'] = getTimestamp(header)\n",
    "    post['user'] = getUser(header)\n",
    "    post['post_id'] = getPostID(header)\n",
    "    post['text'] = getText(body)\n",
    "    post['has_quote'] = True if getQuote(body) else False\n",
    "    post['quotes'] = getQuote(body)\n",
    "    post['shares'] = getLikesShares(body)[1]\n",
    "    post['likes'] = getLikesShares(body)[0]\n",
    "    post['retrieved'] = datetime.now().strftime(\"%H:%M:%S %d-%m-%Y\")\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve posts from thread\n",
    "def parse_thread(thread):\n",
    "    page = 0 # start from the first page\n",
    "    next_page = True\n",
    "    index_post = ''\n",
    "    previous_index_post = ''\n",
    "\n",
    "    data = []\n",
    "\n",
    "    while next_page:\n",
    "        start_url = 'https://www.nairaland.com/{}/{}'.format(thread, page)\n",
    "        r1 = requests.get(start_url, heads)\n",
    "        thread_html = BeautifulSoup(r1.text, 'lxml')\n",
    "\n",
    "        headers = thread_html.find_all('td', class_='bold l pu')\n",
    "        bodys = thread_html.find_all('td', class_='l w pd')\n",
    "\n",
    "        #retrieve first post in the thread\n",
    "        if len(headers) > 1:\n",
    "            index_post = getPostID(headers[0]) \n",
    "\n",
    "        if page > 1:\n",
    "            # compare first post on current page with previous page\n",
    "            if is_post_equal(index_post, previous_index_post):\n",
    "                break\n",
    "        for i in range(len(headers)):\n",
    "            header = headers[i]\n",
    "            body = bodys[i]\n",
    "            post = parse_post(header, body)\n",
    "            post.update({'page_no': page, 'thread':thread})\n",
    "            data.append(post)\n",
    "        \n",
    "        previous_index_post = index_post\n",
    "        page += 1\n",
    "\n",
    "    print('Thread: {} Page: {} No of Posts {}'.format(thread, page, len(data)))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_forum(forum):\n",
    "    start_url = 'https://www.nairaland.com/{}/'.format(forum)\n",
    "    r1 = requests.get(start_url, heads)\n",
    "    raw_html = BeautifulSoup(r1.text, 'html5lib')\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # retrieve the number of pages in the forum\n",
    "    page = 2 #int(raw_html.select('body > div > p:nth-child(7)')[0].select('b')[1].text) #\n",
    "    \n",
    "    for i in tqdm(range(page)):\n",
    "        next_page = start_url + '{}'.format(i)\n",
    "        r2 = requests.get(next_page, heads)\n",
    "        forum_html = BeautifulSoup(r2.text, 'html5lib')\n",
    "        links = raw_html.find_all('a')\n",
    "        for link in links:\n",
    "            thread = get_thread(link)\n",
    "            if thread:\n",
    "                res = parse_thread(thread)\n",
    "                df_res = pd.DataFrame(res)\n",
    "                df_res['forum'] = forum\n",
    "                data.append(df_res)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread: 1809328 Page: 15 No of Posts 471\n"
     ]
    }
   ],
   "source": [
    "data = parse_thread('1809328')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('nairaland': conda)",
   "language": "python",
   "name": "python37664bitnairalandconda4ff64808d17c4bb386b7d70efa356c03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
